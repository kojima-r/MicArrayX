<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>micarrayx.localization.music API documentation</title>
<meta name="description" content="command: micarrayx-localize-music" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>micarrayx.localization.music</code></h1>
</header>
<section id="section-intro">
<p>command: micarrayx-localize-music</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># -*- coding: utf-8 -*-
&#34;&#34;&#34; command: micarrayx-localize-music
&#34;&#34;&#34;
import sys
import numpy as np
import argparse
import json
from scipy import hamming, interpolate, linalg

import matplotlib

matplotlib.use(&#34;Agg&#34;)
import matplotlib.pyplot as plt
import seaborn as sns

sns.set()
import matplotlib.pyplot as plt
import matplotlib.cm as cm

import micarrayx
from hark_tf.read_mat import read_hark_tf
from hark_tf.read_param import read_hark_tf_param


def slice_window(x, win_size, step):
    l = x.shape[0]
    N = win_size
    M = int(np.ceil(float(l - N + step) / step))
    out = []
    for m in range(M):
        start = step * m
        if start + N &lt;= l:
            out.append(x[start : start + N])
    o = np.stack(out, axis=0)
    return o


def estimate_spatial_correlation(spec, win_size, step):
    &#34;&#34;&#34; 空間相関行列の計算 (einsumを使った実装)

    Args:
        spec (ndarray): 入力信号(channel x #frame x frequency_bin)
        win_size (int):   窓幅
        step (int):  シフト幅

    Returns:
        ndarray: STFTの結果：スペクトログラム(#block x frequency_bin x channel x channel)
        - 複数フレームを用いてブロックを構成する(構成時のパラメータがwin_size, step)

    &#34;&#34;&#34;
    # ch,frame,spec -&gt; frame,spec,ch
    x = np.transpose(spec, (1, 2, 0))
    # data: frame,block,spec,ch
    data = slice_window(x, win_size, step)
    a = np.transpose(data, (0, 2, 3, 1))
    b = np.transpose(data, (0, 2, 1, 3)).conj()
    c = np.einsum(&#34;ijkl,ijlm-&gt;ijkm&#34;, a, b)
    # out_corr: frame,spec,ch1,ch2
    out_corr = c * 1.0 / win_size
    # print c[0,0]
    return out_corr


def estimate_spatial_correlation2(spec, win_size, step):
    &#34;&#34;&#34; 空間相関行列の計算2 (ループを使った実装)

    Args:
        spec (ndarray): 入力信号(channel x #frame x frequency_bin)
        win_size (int):   窓幅
        step (int):  シフト幅

    Returns:
        ndarray: STFTの結果：スペクトログラム(#block x frequency_bin x channel x channel)
        - 複数フレームを用いてブロックを構成する(構成時のパラメータがwin_size, step)

    &#34;&#34;&#34;

    # ch,frame,spec -&gt; frame,spec,ch
    n_ch = spec.shape[0]
    n_frame = spec.shape[1]
    n_bin = spec.shape[2]
    corr = np.zeros((n_frame, n_bin, n_ch, n_ch), dtype=complex)

    # out_corr: frame,spec,ch1,ch2
    for i in range(n_ch):
        for j in range(n_ch):
            corr[:, :, i, j] = spec[i] * spec[j].conj()
    now_frame = 0
    out = []
    while now_frame + win_size &lt;= n_frame:
        o = np.mean(corr[now_frame : now_frame + win_size], axis=0)
        out.append(o)
        now_frame += step
    return np.array(out)


f = [
    10.0,
    12.5,
    16.0,
    20.0,
    31.5,
    63.0,
    125.0,
    250.0,
    500.0,
    1000.0,
    2000.0,
    4000.0,
    8000.0,
    12500.0,
    16000.0,
    20000.0,
]
w = [
    np.power(10.0, -70.4 / 20.0),
    np.power(10.0, -63.4 / 20.0),
    np.power(10.0, -56.7 / 20.0),
    np.power(10.0, -50.5 / 20.0),
    np.power(10.0, -39.4 / 20.0),
    np.power(10.0, -26.2 / 20.0),
    np.power(10.0, -16.1 / 20.0),
    np.power(10.0, -8.6 / 20.0),
    np.power(10.0, -3.2 / 20.0),
    np.power(10.0, 0.0 / 20.0),
    np.power(10.0, 1.2 / 20.0),
    np.power(10.0, 1.0 / 20.0),
    np.power(10.0, -1.1 / 20.0),
    np.power(10.0, -4.3 / 20.0),
    np.power(10.0, -6.6 / 20.0),
    np.power(10.0, -9.3 / 20.0),
]
f1 = interpolate.interp1d(f, w, kind=&#34;cubic&#34;)


def A_characteristic(freq):
    &#34;&#34;&#34; A特性の計算
    
    予め用意したテーブルからA特性を計算して返す
    
    &#34;&#34;&#34;
    return f1(freq)


def compute_music_spec(
    spec, src_num, tf_config, df, min_freq_bin=0, win_size=50, step=50, weight_type=&#34;uniform&#34;
):
    &#34;&#34;&#34; 空間パワー（MUSIC spectrum）の計算

    Args:
        spec (ndarray): 入力信号(channel x #frame x frequency_bin)
        src_num (int): 想定音源数
        tf_config (Dict): HARK_TF_PARSERで取得できる伝達関数
        df: 周波数ビンあたりの周波数： フーリエ変換字のパラメータから計算される
        min_freq_bin (int): 計算に使う最小周波数ビン（ノイズの多い低周波を無視するため）
        win_size (int):   窓幅
        step (int):  シフト幅
        weight_type (str): 周波数ビンの重みのタイプ(&#34;uniform&#34;: 一様, &#34;A&#34;:A特性)

    Returns:
        ndarray: STFTの結果：スペクトログラム(#block x frequency_bin x k)
        - k: 方向のインデックス

    &#34;&#34;&#34;
    corr = estimate_spatial_correlation(spec, win_size, step)
    power = np.zeros(
        (corr.shape[0], corr.shape[1], len(tf_config[&#34;tf&#34;])), dtype=complex
    )
    for frame, freq in np.ndindex((corr.shape[0], corr.shape[1])):
        # normalize correlation
        rxx = corr[frame, freq]
        r = rxx / np.max(np.absolute(rxx)+1.0e-20)
        # eigen value decomposition
        e_val, e_vec = np.linalg.eig(r)
        # sort
        eigen_id = np.argsort(e_val)[::-1]
        e_val = e_val[eigen_id]
        e_vec = e_vec[:, eigen_id]
        e = e_vec[:, src_num:]
        # frequency weight
        if weight_type==&#34;A&#34;:
            weight = A_characteristic((min_freq_bin + freq) * df)
        else: # uniform
            weight = 1.0/corr.shape[1]
        # directions
        for k, v in list(tf_config[&#34;tf&#34;].items()):
            a_vec = v[&#34;mat&#34;][:, min_freq_bin + freq]
            a_vec = a_vec / np.absolute(a_vec)
            s = np.dot(a_vec.conj(), e)
            power[frame, freq, k] = (
                weight * np.dot(a_vec.conj(), a_vec) / np.dot(s, s.conj())
            )
    return power


def save_heatmap_music_spec(outfilename_heat, m_power):
    ax = sns.heatmap(m_power.transpose(), cbar=False, cmap=cm.Greys)
    plt.axis(&#34;off&#34;)
    sns.despine(
        fig=None,
        ax=None,
        top=False,
        right=False,
        left=False,
        bottom=False,
        offset=None,
        trim=False,
    )
    plt.tight_layout()
    ax.tick_params(labelbottom=&#34;off&#34;)
    ax.tick_params(labelleft=&#34;off&#34;)
    plt.savefig(outfilename_heat, bbox_inches=&#34;tight&#34;, pad_inches=0.0)
    print(&#34;[save]&#34;, outfilename_heat)


def save_heatmap_music_spec_with_bar(outfilename_heat_bar, m_power):
    plt.clf()
    sns.heatmap(m_power, cbar=True, cmap=cm.Greys)
    plt.savefig(outfilename_heat_bar, bbox_inches=&#34;tight&#34;, pad_inches=0.0)
    plt.clf()
    print(&#34;[save]&#34;, outfilename_heat_bar)


def save_spectrogram(outfilename_fft, spec, ch=0):
    x = np.absolute(spec[ch].T)
    ax = sns.heatmap(x[::-1, :], cbar=False, cmap=&#34;coolwarm&#34;)
    plt.axis(&#34;off&#34;)
    sns.despine(
        fig=None,
        ax=None,
        top=False,
        right=False,
        left=False,
        bottom=False,
        offset=None,
        trim=False,
    )
    plt.tight_layout()
    ax.tick_params(labelbottom=&#34;off&#34;)
    ax.tick_params(labelleft=&#34;off&#34;)
    plt.savefig(outfilename_fft, bbox_inches=&#34;tight&#34;, pad_inches=0.0)
    print(&#34;[save]&#34;, outfilename_fft)


def compute_music_power(
    wav_filename,
    tf_config,
    normalize_factor,
    fftLen,
    stft_step,
    min_freq,
    max_freq,
    src_num,
    music_win_size,
    music_step,
    weight_type=&#34;uniform&#34;,
):
    &#34;&#34;&#34; wavファイルからの空間パワー（MUSIC spectrum）の計算

    Args:
        wav_filename (str): 入力wavファイル名
        tf_config (Dict): HARK_TF_PARSERで取得できる伝達関数
        normalize_factor: 入力波形/ normalize_factor　として入力波形の調整をする
        src_num (int): 想定音源数(MUSIC法パラメータ)
        min_freq (int): 計算に使う最小周波数（ノイズの多い低周波を無視するため）
        max_freq (int): 計算に使う最大周波数（ノイズの多い高周波を無視するため）
        fftLen (int):   窓幅
        stft_step (int):  シフト幅
        music_win_size (int):   窓幅
        music_step (int):  シフト幅
        weight_type (str): 周波数ビンの重みのタイプ(&#34;uniform&#34;: 一様, &#34;A&#34;:A特性)

    Returns:
        ndarray: STFTの結果：スペクトログラム(#block x frequency_bin x k)
        - spec: stftの結果
        - m_power: 空間パワー 周波数について平均化した結果 (#block x k)
        - m_full_power: 空間パワー (#block x frequency_bin x k)
        - setting: 各種セッティング

    &#34;&#34;&#34;
    setting = {}
    # read wav
    print(&#34;... reading&#34;, wav_filename)
    wav_data = micarrayx.read_mch_wave(wav_filename)
    wav = wav_data[&#34;wav&#34;] / normalize_factor
    fs = wav_data[&#34;framerate&#34;]
    # print info
    print(&#34;# #channels : &#34;, wav_data[&#34;nchannels&#34;])
    setting[&#34;nchannels&#34;] = wav_data[&#34;nchannels&#34;]
    print(&#34;# sample size : &#34;, wav.shape[1])
    setting[&#34;nsamples&#34;] = wav.shape[1]
    print(&#34;# sampling rate : &#34;, fs, &#34;Hz&#34;)
    setting[&#34;framerate&#34;] = fs
    print(&#34;# duration : &#34;, wav_data[&#34;duration&#34;], &#34;sec&#34;)
    setting[&#34;duration&#34;] = wav_data[&#34;duration&#34;]

    # reading data
    df = fs * 1.0 / fftLen
    # cutoff bin
    min_freq_bin = int(np.ceil(min_freq / df))
    max_freq_bin = int(np.floor(max_freq / df))
    print(&#34;# min freq. :&#34;, min_freq_bin * df, &#34;Hz&#34;)
    setting[&#34;min_freq&#34;] = min_freq_bin * df
    print(&#34;# max freq. :&#34;, max_freq_bin * df, &#34;Hz&#34;)
    setting[&#34;max_freq&#34;] = max_freq_bin * df
    print(&#34;# freq. step:&#34;, df, &#34;Hz&#34;)
    setting[&#34;freq_step&#34;] = df
    print(&#34;# min freq. bin index:&#34;, min_freq_bin)
    print(&#34;# max freq. bin index:&#34;, max_freq_bin)

    # apply STFT
    win = hamming(fftLen)  # ハミング窓
    spec = micarrayx.stft_mch(wav, win, stft_step)
    spec_m = spec[:, :, min_freq_bin:max_freq_bin]
    # apply MUSIC method
    ## power[frame, freq, direction_id]
    print(&#34;# src_num:&#34;, src_num)
    setting[&#34;src_num&#34;] = src_num
    setting[&#34;step_ms&#34;] = 1000.0 / fs * stft_step
    setting[&#34;music_step_ms&#34;] = 1000.0 / fs * stft_step * music_step
    power = compute_music_spec(
        spec_m,
        src_num,
        tf_config,
        df,
        min_freq_bin,
        win_size=music_win_size,
        step=music_step,
        weight_type=weight_type,
    )
    p = np.sum(np.real(power), axis=1)
    m_power = 10 * np.log10(p + 1.0)
    m_full_power = 10 * np.log10(np.real(power) + 1.0)
    return spec, m_power, m_full_power, setting


def main():
    # argv check
    parser = argparse.ArgumentParser(
        description=&#34;applying the MUSIC method to am-ch wave file&#34;
    )
    parser.add_argument(
        &#34;tf_filename&#34;,
        metavar=&#34;TF_FILE&#34;,
        type=str,
        help=&#34;HARK2.0 transfer function file (.zip)&#34;,
    )
    parser.add_argument(
        &#34;wav_filename&#34;, metavar=&#34;WAV_FILE&#34;, type=str, help=&#34;target wav file&#34;
    )
    parser.add_argument(
        &#34;--normalize_factor&#34;,
        metavar=&#34;V&#34;,
        type=int,
        default=32768.0,
        help=&#34;normalize factor for the given wave data(default=sugned 16bit)&#34;,
    )
    parser.add_argument(
        &#34;--stft_win_size&#34;,
        metavar=&#34;S&#34;,
        type=int,
        default=512,
        help=&#34;window sise for STFT&#34;,
    )
    parser.add_argument(
        &#34;--stft_step&#34;,
        metavar=&#34;S&#34;,
        type=int,
        default=128,
        help=&#34;advance step size for STFT (c.f. overlap=fftLen-step)&#34;,
    )
    parser.add_argument(
        &#34;--min_freq&#34;,
        metavar=&#34;F&#34;,
        type=float,
        default=300,
        help=&#34;minimum frequency of MUSIC spectrogram (Hz)&#34;,
    )
    parser.add_argument(
        &#34;--max_freq&#34;,
        metavar=&#34;F&#34;,
        type=float,
        default=8000,
        help=&#34;maximum frequency of MUSIC spectrogram (Hz)&#34;,
    )
    parser.add_argument(
        &#34;--music_win_size&#34;,
        metavar=&#34;S&#34;,
        type=int,
        default=50,
        help=&#34;block size to compute a correlation matrix for the MUSIC method (frame)&#34;,
    )
    parser.add_argument(
        &#34;--music_step&#34;,
        metavar=&#34;S&#34;,
        type=int,
        default=50,
        help=&#34;advanced step block size (i.e. frequency of computing MUSIC spectrum) (frame)&#34;,
    )
    parser.add_argument(
        &#34;--music_weight_type&#34;,
        choices=[&#34;uniform&#34;,&#34;A&#34;],
        default=&#34;uniform&#34;,
        help=&#34;weight of bins of frequencies&#34;,
    )
    parser.add_argument(
        &#34;--music_src_num&#34;,
        metavar=&#34;N&#34;,
        type=int,
        default=3,
        help=&#34;the number of sound source candidates  (i.e. # of dimensions of the signal subspaces)&#34;,
    )
    parser.add_argument(
        &#34;--out_npy&#34;,
        metavar=&#34;NPY_FILE&#34;,
        type=str,
        default=None,
        help=&#34;[output] numpy file to save MUSIC spectrogram (time,direction=&gt; power)&#34;,
    )
    parser.add_argument(
        &#34;--out_full_npy&#34;,
        metavar=&#34;NPY_FILE&#34;,
        type=str,
        default=None,
        help=&#34;[output] numpy file to save MUSIC spectrogram (time,frequency,direction=&gt; power&#34;,
    )
    parser.add_argument(
        &#34;--out_fig&#34;,
        metavar=&#34;FIG_FILE&#34;,
        type=str,
        default=None,
        help=&#34;[output] fig file to save MUSIC spectrogram (.png)&#34;,
    )
    parser.add_argument(
        &#34;--out_fig_with_bar&#34;,
        metavar=&#34;FIG_FILE&#34;,
        type=str,
        default=None,
        help=&#34;[output] fig file to save MUSIC spectrogram with color bar(.png)&#34;,
    )
    parser.add_argument(
        &#34;--out_spectrogram&#34;,
        metavar=&#34;FIG_FILE&#34;,
        type=str,
        default=None,
        help=&#34;[output] fig file to save power spectrogram (first channel) (.png)&#34;,
    )
    parser.add_argument(
        &#34;--out_setting&#34;,
        metavar=&#34;SETTING_FILE&#34;,
        type=str,
        default=None,
        help=&#34;[output] stting file (.json)&#34;,
    )

    args = parser.parse_args()
    if not args:
        quit()

    # read tf
    print(&#34;... reading&#34;, args.tf_filename)
    tf_config = read_hark_tf(args.tf_filename)

    # print positions of microphones
    # mic_pos=read_hark_tf_param(args.tf_filename)
    # print &#34;# mic positions:&#34;,mic_pos

    spec, m_power, m_full_power, setting = compute_music_power(
        args.wav_filename,
        tf_config,
        args.normalize_factor,
        args.stft_win_size,
        args.stft_step,
        args.min_freq,
        args.max_freq,
        args.music_src_num,
        args.music_win_size,
        args.music_step,
    )

    # save setting
    if args.out_setting:
        outfilename = args.out_setting
        fp = open(outfilename, &#34;w&#34;)
        json.dump(setting, fp, sort_keys=True, indent=2)
        print(&#34;[save]&#34;, outfilename)
    # save MUSIC spectrogram
    if args.out_npy:
        outfilename = args.out_npy
        np.save(outfilename, m_power)
        print(&#34;[save]&#34;, outfilename)
    # save MUSIC spectrogram for each freq.
    if args.out_full_npy:
        outfilename = args.out_full_npy
        np.save(outfilename, m_full_power)
        print(&#34;[save]&#34;, outfilename)
    # plot heat map
    if args.out_fig:
        save_heatmap_music_spec(args.out_fig, m_power)
    # plot heat map with color bar
    if args.out_fig_with_bar:
        save_heatmap_music_spec_with_bar(args.out_fig_with_bar, m_power)
    # plot spectrogram
    if args.out_spectrogram:
        save_spectrogram(args.out_spectrogram, spec, ch=0)
if __name__ == &#34;__main__&#34;:
    main()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="micarrayx.localization.music.A_characteristic"><code class="name flex">
<span>def <span class="ident">A_characteristic</span></span>(<span>freq)</span>
</code></dt>
<dd>
<div class="desc"><p>A特性の計算</p>
<p>予め用意したテーブルからA特性を計算して返す</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def A_characteristic(freq):
    &#34;&#34;&#34; A特性の計算
    
    予め用意したテーブルからA特性を計算して返す
    
    &#34;&#34;&#34;
    return f1(freq)</code></pre>
</details>
</dd>
<dt id="micarrayx.localization.music.compute_music_power"><code class="name flex">
<span>def <span class="ident">compute_music_power</span></span>(<span>wav_filename, tf_config, normalize_factor, fftLen, stft_step, min_freq, max_freq, src_num, music_win_size, music_step, weight_type='uniform')</span>
</code></dt>
<dd>
<div class="desc"><p>wavファイルからの空間パワー（MUSIC spectrum）の計算</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>wav_filename</code></strong> :&ensp;<code>str</code></dt>
<dd>入力wavファイル名</dd>
<dt><strong><code>tf_config</code></strong> :&ensp;<code>Dict</code></dt>
<dd>HARK_TF_PARSERで取得できる伝達関数</dd>
<dt><strong><code>normalize_factor</code></strong></dt>
<dd>入力波形/ normalize_factor　として入力波形の調整をする</dd>
<dt><strong><code>src_num</code></strong> :&ensp;<code>int</code></dt>
<dd>想定音源数(MUSIC法パラメータ)</dd>
<dt><strong><code>min_freq</code></strong> :&ensp;<code>int</code></dt>
<dd>計算に使う最小周波数（ノイズの多い低周波を無視するため）</dd>
<dt><strong><code>max_freq</code></strong> :&ensp;<code>int</code></dt>
<dd>計算に使う最大周波数（ノイズの多い高周波を無視するため）</dd>
<dt><strong><code>fftLen</code></strong> :&ensp;<code>int</code></dt>
<dd>窓幅</dd>
<dt><strong><code>stft_step</code></strong> :&ensp;<code>int</code></dt>
<dd>シフト幅</dd>
<dt><strong><code>music_win_size</code></strong> :&ensp;<code>int</code></dt>
<dd>窓幅</dd>
<dt><strong><code>music_step</code></strong> :&ensp;<code>int</code></dt>
<dd>シフト幅</dd>
<dt><strong><code>weight_type</code></strong> :&ensp;<code>str</code></dt>
<dd>周波数ビンの重みのタイプ("uniform": 一様, "A":A特性)</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>ndarray</code></dt>
<dd>STFTの結果：スペクトログラム(#block x frequency_bin x k)</dd>
</dl>
<ul>
<li>spec: stftの結果</li>
<li>m_power: 空間パワー 周波数について平均化した結果 (#block x k)</li>
<li>m_full_power: 空間パワー (#block x frequency_bin x k)</li>
<li>setting: 各種セッティング</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_music_power(
    wav_filename,
    tf_config,
    normalize_factor,
    fftLen,
    stft_step,
    min_freq,
    max_freq,
    src_num,
    music_win_size,
    music_step,
    weight_type=&#34;uniform&#34;,
):
    &#34;&#34;&#34; wavファイルからの空間パワー（MUSIC spectrum）の計算

    Args:
        wav_filename (str): 入力wavファイル名
        tf_config (Dict): HARK_TF_PARSERで取得できる伝達関数
        normalize_factor: 入力波形/ normalize_factor　として入力波形の調整をする
        src_num (int): 想定音源数(MUSIC法パラメータ)
        min_freq (int): 計算に使う最小周波数（ノイズの多い低周波を無視するため）
        max_freq (int): 計算に使う最大周波数（ノイズの多い高周波を無視するため）
        fftLen (int):   窓幅
        stft_step (int):  シフト幅
        music_win_size (int):   窓幅
        music_step (int):  シフト幅
        weight_type (str): 周波数ビンの重みのタイプ(&#34;uniform&#34;: 一様, &#34;A&#34;:A特性)

    Returns:
        ndarray: STFTの結果：スペクトログラム(#block x frequency_bin x k)
        - spec: stftの結果
        - m_power: 空間パワー 周波数について平均化した結果 (#block x k)
        - m_full_power: 空間パワー (#block x frequency_bin x k)
        - setting: 各種セッティング

    &#34;&#34;&#34;
    setting = {}
    # read wav
    print(&#34;... reading&#34;, wav_filename)
    wav_data = micarrayx.read_mch_wave(wav_filename)
    wav = wav_data[&#34;wav&#34;] / normalize_factor
    fs = wav_data[&#34;framerate&#34;]
    # print info
    print(&#34;# #channels : &#34;, wav_data[&#34;nchannels&#34;])
    setting[&#34;nchannels&#34;] = wav_data[&#34;nchannels&#34;]
    print(&#34;# sample size : &#34;, wav.shape[1])
    setting[&#34;nsamples&#34;] = wav.shape[1]
    print(&#34;# sampling rate : &#34;, fs, &#34;Hz&#34;)
    setting[&#34;framerate&#34;] = fs
    print(&#34;# duration : &#34;, wav_data[&#34;duration&#34;], &#34;sec&#34;)
    setting[&#34;duration&#34;] = wav_data[&#34;duration&#34;]

    # reading data
    df = fs * 1.0 / fftLen
    # cutoff bin
    min_freq_bin = int(np.ceil(min_freq / df))
    max_freq_bin = int(np.floor(max_freq / df))
    print(&#34;# min freq. :&#34;, min_freq_bin * df, &#34;Hz&#34;)
    setting[&#34;min_freq&#34;] = min_freq_bin * df
    print(&#34;# max freq. :&#34;, max_freq_bin * df, &#34;Hz&#34;)
    setting[&#34;max_freq&#34;] = max_freq_bin * df
    print(&#34;# freq. step:&#34;, df, &#34;Hz&#34;)
    setting[&#34;freq_step&#34;] = df
    print(&#34;# min freq. bin index:&#34;, min_freq_bin)
    print(&#34;# max freq. bin index:&#34;, max_freq_bin)

    # apply STFT
    win = hamming(fftLen)  # ハミング窓
    spec = micarrayx.stft_mch(wav, win, stft_step)
    spec_m = spec[:, :, min_freq_bin:max_freq_bin]
    # apply MUSIC method
    ## power[frame, freq, direction_id]
    print(&#34;# src_num:&#34;, src_num)
    setting[&#34;src_num&#34;] = src_num
    setting[&#34;step_ms&#34;] = 1000.0 / fs * stft_step
    setting[&#34;music_step_ms&#34;] = 1000.0 / fs * stft_step * music_step
    power = compute_music_spec(
        spec_m,
        src_num,
        tf_config,
        df,
        min_freq_bin,
        win_size=music_win_size,
        step=music_step,
        weight_type=weight_type,
    )
    p = np.sum(np.real(power), axis=1)
    m_power = 10 * np.log10(p + 1.0)
    m_full_power = 10 * np.log10(np.real(power) + 1.0)
    return spec, m_power, m_full_power, setting</code></pre>
</details>
</dd>
<dt id="micarrayx.localization.music.compute_music_spec"><code class="name flex">
<span>def <span class="ident">compute_music_spec</span></span>(<span>spec, src_num, tf_config, df, min_freq_bin=0, win_size=50, step=50, weight_type='uniform')</span>
</code></dt>
<dd>
<div class="desc"><p>空間パワー（MUSIC spectrum）の計算</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>spec</code></strong> :&ensp;<code>ndarray</code></dt>
<dd>入力信号(channel x #frame x frequency_bin)</dd>
<dt><strong><code>src_num</code></strong> :&ensp;<code>int</code></dt>
<dd>想定音源数</dd>
<dt><strong><code>tf_config</code></strong> :&ensp;<code>Dict</code></dt>
<dd>HARK_TF_PARSERで取得できる伝達関数</dd>
<dt><strong><code>df</code></strong></dt>
<dd>周波数ビンあたりの周波数： フーリエ変換字のパラメータから計算される</dd>
<dt><strong><code>min_freq_bin</code></strong> :&ensp;<code>int</code></dt>
<dd>計算に使う最小周波数ビン（ノイズの多い低周波を無視するため）</dd>
<dt><strong><code>win_size</code></strong> :&ensp;<code>int</code></dt>
<dd>窓幅</dd>
<dt><strong><code>step</code></strong> :&ensp;<code>int</code></dt>
<dd>シフト幅</dd>
<dt><strong><code>weight_type</code></strong> :&ensp;<code>str</code></dt>
<dd>周波数ビンの重みのタイプ("uniform": 一様, "A":A特性)</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>ndarray</code></dt>
<dd>STFTの結果：スペクトログラム(#block x frequency_bin x k)</dd>
</dl>
<ul>
<li>k: 方向のインデックス</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_music_spec(
    spec, src_num, tf_config, df, min_freq_bin=0, win_size=50, step=50, weight_type=&#34;uniform&#34;
):
    &#34;&#34;&#34; 空間パワー（MUSIC spectrum）の計算

    Args:
        spec (ndarray): 入力信号(channel x #frame x frequency_bin)
        src_num (int): 想定音源数
        tf_config (Dict): HARK_TF_PARSERで取得できる伝達関数
        df: 周波数ビンあたりの周波数： フーリエ変換字のパラメータから計算される
        min_freq_bin (int): 計算に使う最小周波数ビン（ノイズの多い低周波を無視するため）
        win_size (int):   窓幅
        step (int):  シフト幅
        weight_type (str): 周波数ビンの重みのタイプ(&#34;uniform&#34;: 一様, &#34;A&#34;:A特性)

    Returns:
        ndarray: STFTの結果：スペクトログラム(#block x frequency_bin x k)
        - k: 方向のインデックス

    &#34;&#34;&#34;
    corr = estimate_spatial_correlation(spec, win_size, step)
    power = np.zeros(
        (corr.shape[0], corr.shape[1], len(tf_config[&#34;tf&#34;])), dtype=complex
    )
    for frame, freq in np.ndindex((corr.shape[0], corr.shape[1])):
        # normalize correlation
        rxx = corr[frame, freq]
        r = rxx / np.max(np.absolute(rxx)+1.0e-20)
        # eigen value decomposition
        e_val, e_vec = np.linalg.eig(r)
        # sort
        eigen_id = np.argsort(e_val)[::-1]
        e_val = e_val[eigen_id]
        e_vec = e_vec[:, eigen_id]
        e = e_vec[:, src_num:]
        # frequency weight
        if weight_type==&#34;A&#34;:
            weight = A_characteristic((min_freq_bin + freq) * df)
        else: # uniform
            weight = 1.0/corr.shape[1]
        # directions
        for k, v in list(tf_config[&#34;tf&#34;].items()):
            a_vec = v[&#34;mat&#34;][:, min_freq_bin + freq]
            a_vec = a_vec / np.absolute(a_vec)
            s = np.dot(a_vec.conj(), e)
            power[frame, freq, k] = (
                weight * np.dot(a_vec.conj(), a_vec) / np.dot(s, s.conj())
            )
    return power</code></pre>
</details>
</dd>
<dt id="micarrayx.localization.music.estimate_spatial_correlation"><code class="name flex">
<span>def <span class="ident">estimate_spatial_correlation</span></span>(<span>spec, win_size, step)</span>
</code></dt>
<dd>
<div class="desc"><p>空間相関行列の計算 (einsumを使った実装)</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>spec</code></strong> :&ensp;<code>ndarray</code></dt>
<dd>入力信号(channel x #frame x frequency_bin)</dd>
<dt><strong><code>win_size</code></strong> :&ensp;<code>int</code></dt>
<dd>窓幅</dd>
<dt><strong><code>step</code></strong> :&ensp;<code>int</code></dt>
<dd>シフト幅</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>ndarray</code></dt>
<dd>STFTの結果：スペクトログラム(#block x frequency_bin x channel x channel)</dd>
</dl>
<ul>
<li>複数フレームを用いてブロックを構成する(構成時のパラメータがwin_size, step)</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def estimate_spatial_correlation(spec, win_size, step):
    &#34;&#34;&#34; 空間相関行列の計算 (einsumを使った実装)

    Args:
        spec (ndarray): 入力信号(channel x #frame x frequency_bin)
        win_size (int):   窓幅
        step (int):  シフト幅

    Returns:
        ndarray: STFTの結果：スペクトログラム(#block x frequency_bin x channel x channel)
        - 複数フレームを用いてブロックを構成する(構成時のパラメータがwin_size, step)

    &#34;&#34;&#34;
    # ch,frame,spec -&gt; frame,spec,ch
    x = np.transpose(spec, (1, 2, 0))
    # data: frame,block,spec,ch
    data = slice_window(x, win_size, step)
    a = np.transpose(data, (0, 2, 3, 1))
    b = np.transpose(data, (0, 2, 1, 3)).conj()
    c = np.einsum(&#34;ijkl,ijlm-&gt;ijkm&#34;, a, b)
    # out_corr: frame,spec,ch1,ch2
    out_corr = c * 1.0 / win_size
    # print c[0,0]
    return out_corr</code></pre>
</details>
</dd>
<dt id="micarrayx.localization.music.estimate_spatial_correlation2"><code class="name flex">
<span>def <span class="ident">estimate_spatial_correlation2</span></span>(<span>spec, win_size, step)</span>
</code></dt>
<dd>
<div class="desc"><p>空間相関行列の計算2 (ループを使った実装)</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>spec</code></strong> :&ensp;<code>ndarray</code></dt>
<dd>入力信号(channel x #frame x frequency_bin)</dd>
<dt><strong><code>win_size</code></strong> :&ensp;<code>int</code></dt>
<dd>窓幅</dd>
<dt><strong><code>step</code></strong> :&ensp;<code>int</code></dt>
<dd>シフト幅</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>ndarray</code></dt>
<dd>STFTの結果：スペクトログラム(#block x frequency_bin x channel x channel)</dd>
</dl>
<ul>
<li>複数フレームを用いてブロックを構成する(構成時のパラメータがwin_size, step)</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def estimate_spatial_correlation2(spec, win_size, step):
    &#34;&#34;&#34; 空間相関行列の計算2 (ループを使った実装)

    Args:
        spec (ndarray): 入力信号(channel x #frame x frequency_bin)
        win_size (int):   窓幅
        step (int):  シフト幅

    Returns:
        ndarray: STFTの結果：スペクトログラム(#block x frequency_bin x channel x channel)
        - 複数フレームを用いてブロックを構成する(構成時のパラメータがwin_size, step)

    &#34;&#34;&#34;

    # ch,frame,spec -&gt; frame,spec,ch
    n_ch = spec.shape[0]
    n_frame = spec.shape[1]
    n_bin = spec.shape[2]
    corr = np.zeros((n_frame, n_bin, n_ch, n_ch), dtype=complex)

    # out_corr: frame,spec,ch1,ch2
    for i in range(n_ch):
        for j in range(n_ch):
            corr[:, :, i, j] = spec[i] * spec[j].conj()
    now_frame = 0
    out = []
    while now_frame + win_size &lt;= n_frame:
        o = np.mean(corr[now_frame : now_frame + win_size], axis=0)
        out.append(o)
        now_frame += step
    return np.array(out)</code></pre>
</details>
</dd>
<dt id="micarrayx.localization.music.main"><code class="name flex">
<span>def <span class="ident">main</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def main():
    # argv check
    parser = argparse.ArgumentParser(
        description=&#34;applying the MUSIC method to am-ch wave file&#34;
    )
    parser.add_argument(
        &#34;tf_filename&#34;,
        metavar=&#34;TF_FILE&#34;,
        type=str,
        help=&#34;HARK2.0 transfer function file (.zip)&#34;,
    )
    parser.add_argument(
        &#34;wav_filename&#34;, metavar=&#34;WAV_FILE&#34;, type=str, help=&#34;target wav file&#34;
    )
    parser.add_argument(
        &#34;--normalize_factor&#34;,
        metavar=&#34;V&#34;,
        type=int,
        default=32768.0,
        help=&#34;normalize factor for the given wave data(default=sugned 16bit)&#34;,
    )
    parser.add_argument(
        &#34;--stft_win_size&#34;,
        metavar=&#34;S&#34;,
        type=int,
        default=512,
        help=&#34;window sise for STFT&#34;,
    )
    parser.add_argument(
        &#34;--stft_step&#34;,
        metavar=&#34;S&#34;,
        type=int,
        default=128,
        help=&#34;advance step size for STFT (c.f. overlap=fftLen-step)&#34;,
    )
    parser.add_argument(
        &#34;--min_freq&#34;,
        metavar=&#34;F&#34;,
        type=float,
        default=300,
        help=&#34;minimum frequency of MUSIC spectrogram (Hz)&#34;,
    )
    parser.add_argument(
        &#34;--max_freq&#34;,
        metavar=&#34;F&#34;,
        type=float,
        default=8000,
        help=&#34;maximum frequency of MUSIC spectrogram (Hz)&#34;,
    )
    parser.add_argument(
        &#34;--music_win_size&#34;,
        metavar=&#34;S&#34;,
        type=int,
        default=50,
        help=&#34;block size to compute a correlation matrix for the MUSIC method (frame)&#34;,
    )
    parser.add_argument(
        &#34;--music_step&#34;,
        metavar=&#34;S&#34;,
        type=int,
        default=50,
        help=&#34;advanced step block size (i.e. frequency of computing MUSIC spectrum) (frame)&#34;,
    )
    parser.add_argument(
        &#34;--music_weight_type&#34;,
        choices=[&#34;uniform&#34;,&#34;A&#34;],
        default=&#34;uniform&#34;,
        help=&#34;weight of bins of frequencies&#34;,
    )
    parser.add_argument(
        &#34;--music_src_num&#34;,
        metavar=&#34;N&#34;,
        type=int,
        default=3,
        help=&#34;the number of sound source candidates  (i.e. # of dimensions of the signal subspaces)&#34;,
    )
    parser.add_argument(
        &#34;--out_npy&#34;,
        metavar=&#34;NPY_FILE&#34;,
        type=str,
        default=None,
        help=&#34;[output] numpy file to save MUSIC spectrogram (time,direction=&gt; power)&#34;,
    )
    parser.add_argument(
        &#34;--out_full_npy&#34;,
        metavar=&#34;NPY_FILE&#34;,
        type=str,
        default=None,
        help=&#34;[output] numpy file to save MUSIC spectrogram (time,frequency,direction=&gt; power&#34;,
    )
    parser.add_argument(
        &#34;--out_fig&#34;,
        metavar=&#34;FIG_FILE&#34;,
        type=str,
        default=None,
        help=&#34;[output] fig file to save MUSIC spectrogram (.png)&#34;,
    )
    parser.add_argument(
        &#34;--out_fig_with_bar&#34;,
        metavar=&#34;FIG_FILE&#34;,
        type=str,
        default=None,
        help=&#34;[output] fig file to save MUSIC spectrogram with color bar(.png)&#34;,
    )
    parser.add_argument(
        &#34;--out_spectrogram&#34;,
        metavar=&#34;FIG_FILE&#34;,
        type=str,
        default=None,
        help=&#34;[output] fig file to save power spectrogram (first channel) (.png)&#34;,
    )
    parser.add_argument(
        &#34;--out_setting&#34;,
        metavar=&#34;SETTING_FILE&#34;,
        type=str,
        default=None,
        help=&#34;[output] stting file (.json)&#34;,
    )

    args = parser.parse_args()
    if not args:
        quit()

    # read tf
    print(&#34;... reading&#34;, args.tf_filename)
    tf_config = read_hark_tf(args.tf_filename)

    # print positions of microphones
    # mic_pos=read_hark_tf_param(args.tf_filename)
    # print &#34;# mic positions:&#34;,mic_pos

    spec, m_power, m_full_power, setting = compute_music_power(
        args.wav_filename,
        tf_config,
        args.normalize_factor,
        args.stft_win_size,
        args.stft_step,
        args.min_freq,
        args.max_freq,
        args.music_src_num,
        args.music_win_size,
        args.music_step,
    )

    # save setting
    if args.out_setting:
        outfilename = args.out_setting
        fp = open(outfilename, &#34;w&#34;)
        json.dump(setting, fp, sort_keys=True, indent=2)
        print(&#34;[save]&#34;, outfilename)
    # save MUSIC spectrogram
    if args.out_npy:
        outfilename = args.out_npy
        np.save(outfilename, m_power)
        print(&#34;[save]&#34;, outfilename)
    # save MUSIC spectrogram for each freq.
    if args.out_full_npy:
        outfilename = args.out_full_npy
        np.save(outfilename, m_full_power)
        print(&#34;[save]&#34;, outfilename)
    # plot heat map
    if args.out_fig:
        save_heatmap_music_spec(args.out_fig, m_power)
    # plot heat map with color bar
    if args.out_fig_with_bar:
        save_heatmap_music_spec_with_bar(args.out_fig_with_bar, m_power)
    # plot spectrogram
    if args.out_spectrogram:
        save_spectrogram(args.out_spectrogram, spec, ch=0)</code></pre>
</details>
</dd>
<dt id="micarrayx.localization.music.save_heatmap_music_spec"><code class="name flex">
<span>def <span class="ident">save_heatmap_music_spec</span></span>(<span>outfilename_heat, m_power)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_heatmap_music_spec(outfilename_heat, m_power):
    ax = sns.heatmap(m_power.transpose(), cbar=False, cmap=cm.Greys)
    plt.axis(&#34;off&#34;)
    sns.despine(
        fig=None,
        ax=None,
        top=False,
        right=False,
        left=False,
        bottom=False,
        offset=None,
        trim=False,
    )
    plt.tight_layout()
    ax.tick_params(labelbottom=&#34;off&#34;)
    ax.tick_params(labelleft=&#34;off&#34;)
    plt.savefig(outfilename_heat, bbox_inches=&#34;tight&#34;, pad_inches=0.0)
    print(&#34;[save]&#34;, outfilename_heat)</code></pre>
</details>
</dd>
<dt id="micarrayx.localization.music.save_heatmap_music_spec_with_bar"><code class="name flex">
<span>def <span class="ident">save_heatmap_music_spec_with_bar</span></span>(<span>outfilename_heat_bar, m_power)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_heatmap_music_spec_with_bar(outfilename_heat_bar, m_power):
    plt.clf()
    sns.heatmap(m_power, cbar=True, cmap=cm.Greys)
    plt.savefig(outfilename_heat_bar, bbox_inches=&#34;tight&#34;, pad_inches=0.0)
    plt.clf()
    print(&#34;[save]&#34;, outfilename_heat_bar)</code></pre>
</details>
</dd>
<dt id="micarrayx.localization.music.save_spectrogram"><code class="name flex">
<span>def <span class="ident">save_spectrogram</span></span>(<span>outfilename_fft, spec, ch=0)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_spectrogram(outfilename_fft, spec, ch=0):
    x = np.absolute(spec[ch].T)
    ax = sns.heatmap(x[::-1, :], cbar=False, cmap=&#34;coolwarm&#34;)
    plt.axis(&#34;off&#34;)
    sns.despine(
        fig=None,
        ax=None,
        top=False,
        right=False,
        left=False,
        bottom=False,
        offset=None,
        trim=False,
    )
    plt.tight_layout()
    ax.tick_params(labelbottom=&#34;off&#34;)
    ax.tick_params(labelleft=&#34;off&#34;)
    plt.savefig(outfilename_fft, bbox_inches=&#34;tight&#34;, pad_inches=0.0)
    print(&#34;[save]&#34;, outfilename_fft)</code></pre>
</details>
</dd>
<dt id="micarrayx.localization.music.slice_window"><code class="name flex">
<span>def <span class="ident">slice_window</span></span>(<span>x, win_size, step)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def slice_window(x, win_size, step):
    l = x.shape[0]
    N = win_size
    M = int(np.ceil(float(l - N + step) / step))
    out = []
    for m in range(M):
        start = step * m
        if start + N &lt;= l:
            out.append(x[start : start + N])
    o = np.stack(out, axis=0)
    return o</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="micarrayx.localization" href="index.html">micarrayx.localization</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="micarrayx.localization.music.A_characteristic" href="#micarrayx.localization.music.A_characteristic">A_characteristic</a></code></li>
<li><code><a title="micarrayx.localization.music.compute_music_power" href="#micarrayx.localization.music.compute_music_power">compute_music_power</a></code></li>
<li><code><a title="micarrayx.localization.music.compute_music_spec" href="#micarrayx.localization.music.compute_music_spec">compute_music_spec</a></code></li>
<li><code><a title="micarrayx.localization.music.estimate_spatial_correlation" href="#micarrayx.localization.music.estimate_spatial_correlation">estimate_spatial_correlation</a></code></li>
<li><code><a title="micarrayx.localization.music.estimate_spatial_correlation2" href="#micarrayx.localization.music.estimate_spatial_correlation2">estimate_spatial_correlation2</a></code></li>
<li><code><a title="micarrayx.localization.music.main" href="#micarrayx.localization.music.main">main</a></code></li>
<li><code><a title="micarrayx.localization.music.save_heatmap_music_spec" href="#micarrayx.localization.music.save_heatmap_music_spec">save_heatmap_music_spec</a></code></li>
<li><code><a title="micarrayx.localization.music.save_heatmap_music_spec_with_bar" href="#micarrayx.localization.music.save_heatmap_music_spec_with_bar">save_heatmap_music_spec_with_bar</a></code></li>
<li><code><a title="micarrayx.localization.music.save_spectrogram" href="#micarrayx.localization.music.save_spectrogram">save_spectrogram</a></code></li>
<li><code><a title="micarrayx.localization.music.slice_window" href="#micarrayx.localization.music.slice_window">slice_window</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>